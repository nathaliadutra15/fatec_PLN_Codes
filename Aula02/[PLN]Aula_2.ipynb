{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathaliadutra15/fatec_PLN_Codes/blob/master/Aula02/%5BPLN%5DAula_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 02 - Fundamentos de linguística para PLN"
      ],
      "metadata": {
        "id": "VnyEcpLiMRY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prática 1 - Sintaxe\n",
        "\n",
        "### Exemplo 1 - Demonstração de segmentação, tokenização e uma árvore de dependência\n"
      ],
      "metadata": {
        "id": "SPUpNaL_nKF0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8x8udi_lfLw",
        "outputId": "313c2df5-b390-497b-8997-61366232352d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown fox jumps over the lazy dog. The black cat is walking.\n",
            "\n",
            "Segmentação de Frases:\n",
            "The quick brown fox jumps over the lazy dog.\n",
            "The black cat is walking.\n",
            "\n",
            "teokenização das palavras:\n",
            "1 The DET det\n",
            "2 quick ADJ amod\n",
            "3 brown ADJ amod\n",
            "4 fox NOUN nsubj\n",
            "5 jumps VERB ROOT\n",
            "6 over ADP prep\n",
            "7 the DET det\n",
            "8 lazy ADJ amod\n",
            "9 dog NOUN pobj\n",
            "10 . PUNCT punct\n",
            "11 The DET det\n",
            "12 black ADJ amod\n",
            "13 cat NOUN nsubj\n",
            "14 is AUX aux\n",
            "15 walking VERB ROOT\n",
            "16 . PUNCT punct\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Carregar o modelo de linguagem\n",
        "nlp = spacy.load(\"en_core_web_sm\") # modelo pré treinado para o idioma em inglês\n",
        "\n",
        "# Processar a frase\n",
        "doc = nlp(\"The quick brown fox jumps over the lazy dog. The black cat is walking.\")\n",
        "print(doc)\n",
        "\n",
        "\n",
        "print(\"\\nSegmentação de Frases:\")\n",
        "for sentenca in doc.sents:\n",
        "    print(sentenca.text)\n",
        "\n",
        "i = 1\n",
        "print(\"\\nteokenização das palavras:\")\n",
        "for token in doc:\n",
        "    print(i, token.text, end = ' ') # Visualizar as palavras da frase\n",
        "    print(token.pos_, end = ' ') # visualizar as classes gramaticais\n",
        "    print(token.dep_) # visualiza a estrutura sintática\n",
        "    i += 1\n",
        "\n",
        "#for token in doc:\n",
        "#  print(f\"{token.text:10} {token.pos_:8} {token.dep_:8}\")\n",
        "\n",
        "# Visualizar a árvore graficamente (opcional)\n",
        "from spacy import displacy # importa o modulo de visualização do spaCy\n",
        "\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)\n",
        "\n",
        "\n",
        "#  doc >>> arquivo de texto a ser analisado\n",
        "#  style=\"dep\" >>> a forma como será analisado [dep] indica que será feito uma analise de dependência\n",
        "#  jupyter = true >>> indica que será visualizado dentro do jupiter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 1a - Mesma coisa mas com um modelo pre treinado em português"
      ],
      "metadata": {
        "id": "X801k3ApO1b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ9oSFKVZJaq",
        "outputId": "51219f20-7811-493b-8dc7-725a4680448e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Carregar o modelo para português\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "# Processar um texto em português\n",
        "textoRecebido = input(\"Digite um texto para ser analisado: \")\n",
        "doc = nlp(textoRecebido)\n",
        "\n",
        "print('\\nAnálise gramatical das palavras:')\n",
        "for token in doc:\n",
        "    print(f\"Palavra: {token.text}, Classe: {token.pos_}\")\n",
        "\n",
        "print(\"\\nAnalise de Dependências:\")\n",
        "for token in doc:\n",
        "  print(f\"Palavra: {token.text}, Depende de: {token.head.text}\")\n",
        "\n",
        "# Visualizar a árvore graficamente (opcional)\n",
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "Md3UNij1O8bF",
        "outputId": "758b3f41-71d2-471f-e41d-84cd37c1837b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite um texto para ser analisado: não sei o que escrever.\n",
            "\n",
            "Análise gramatical das palavras:\n",
            "Palavra: não, Classe: ADV\n",
            "Palavra: sei, Classe: VERB\n",
            "Palavra: o, Classe: PRON\n",
            "Palavra: que, Classe: PRON\n",
            "Palavra: escrever, Classe: VERB\n",
            "Palavra: ., Classe: PUNCT\n",
            "\n",
            "Analise de Dependências:\n",
            "Palavra: não, Depende de: sei\n",
            "Palavra: sei, Depende de: sei\n",
            "Palavra: o, Depende de: sei\n",
            "Palavra: que, Depende de: escrever\n",
            "Palavra: escrever, Depende de: o\n",
            "Palavra: ., Depende de: sei\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"5cee8a5e3158444abe169e889c6ebb00-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">não</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">sei</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">o</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">que</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">escrever.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5cee8a5e3158444abe169e889c6ebb00-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5cee8a5e3158444abe169e889c6ebb00-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5cee8a5e3158444abe169e889c6ebb00-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5cee8a5e3158444abe169e889c6ebb00-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5cee8a5e3158444abe169e889c6ebb00-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5cee8a5e3158444abe169e889c6ebb00-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5cee8a5e3158444abe169e889c6ebb00-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5cee8a5e3158444abe169e889c6ebb00-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl:relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outros modelos pre treinado:\n",
        "# Português\n",
        "nlp_pt = spacy.load('pt_core_news_sm')\n",
        "\n",
        "# Inglês\n",
        "nlp_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Espanhol\n",
        "nlp_es = spacy.load('es_core_news_sm')\n",
        "\n",
        "# Francês\n",
        "nlp_fr = spacy.load('fr_core_news_sm')\n",
        "\n",
        "# Alemão\n",
        "nlp_de = spacy.load('de_core_news_sm')\n",
        "\n",
        "Os modelos pré-treinados são como \"cérebros artificiais\" que já foram ensinados a entender e analisar um idioma específico. Vou explicar em detalhes:\n",
        "\n",
        "O que são:\n",
        "\n",
        "Conjuntos de dados estatísticos e regras\n",
        "Treinados com milhões de textos\n",
        "Especializados em tarefas específicas de linguagem\n",
        "Resultado de aprendizado de máquina\n",
        "\n",
        "\n",
        "Como são treinados:\n",
        "\n",
        "Alimentados com grande volume de textos\n",
        "Aprendem padrões do idioma\n",
        "Reconhecem estruturas gramaticais\n",
        "Identificam relações entre palavras\n",
        "São testados e refinados\n",
        "Tipos de modelos por tamanho:\n",
        "\n",
        "Pequeno (sm):\n",
        "\n",
        "Mais rápido\n",
        "Menor precisão\n",
        "Usa menos memória\n",
        "Bom para testes\n",
        "\n",
        "\n",
        "Médio (md):\n",
        "\n",
        "Equilíbrio entre velocidade e precisão\n",
        "Precisão moderada\n",
        "Bom para uso geral\n",
        "\n",
        "\n",
        "Grande (lg):\n",
        "\n",
        "Mais preciso\n",
        "Mais lento\n",
        "Usa mais memória\n",
        "Melhor para análises detalhadas\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Vantagens de usar modelos pré-treinados:\n",
        "\n",
        "Não precisa treinar do zero\n",
        "Economia de tempo e recursos\n",
        "Resultados consistentes\n",
        "Já testados e validados\n",
        "Atualizados regularmente\n"
      ],
      "metadata": {
        "id": "qnzsldfqapzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 2 --  Tokenização e Segmentação com NLTK\n",
        "\n"
      ],
      "metadata": {
        "id": "G59L8FHbOPXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# Download necessário para usar os tokenizadores\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O gato preto pulou sobre o muro. Ele estava com fome e procurava algo para comer.\"\n",
        "print(texto)\n",
        "\n",
        "# Segmentação de frases\n",
        "frases = sent_tokenize(texto)\n",
        "print(\"\\nSegmentação de Frases:\")\n",
        "print(frases)\n",
        "\n",
        "# Tokenização de palavras para cada frase\n",
        "print(\"\\nTokenização de Palavras:\")\n",
        "for frase in frases:\n",
        "    palavras = word_tokenize(frase)\n",
        "    print(palavras)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwrDeWeROSsp",
        "outputId": "0d9eea20-79a1-4276-b90c-2e3db07b9564",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O gato preto pulou sobre o muro. Ele estava com fome e procurava algo para comer.\n",
            "\n",
            "Segmentação de Frases:\n",
            "['O gato preto pulou sobre o muro.', 'Ele estava com fome e procurava algo para comer.']\n",
            "\n",
            "Tokenização de Palavras:\n",
            "['O', 'gato', 'preto', 'pulou', 'sobre', 'o', 'muro', '.']\n",
            "['Ele', 'estava', 'com', 'fome', 'e', 'procurava', 'algo', 'para', 'comer', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prática 2 - Semântica\n",
        "\n",
        "### Exemplo 1"
      ],
      "metadata": {
        "id": "SoI6blIhf2lW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importar o modelo de vetorização da biblioteca gensin\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Crie uma lista de FRASES (listas de palavras)\n",
        "sentences = [\n",
        "    [\"O\", \"gato\", \"subiu\", \"na\", \"árvore\"],# sentences [0][2] subiu\n",
        "    [\"O\", \"cachorro\", \"latiu\", \"para\", \"o\", \"gato\"],\n",
        "    [\"A\", \"bola\", \"rolou\", \"pelo\", \"gramado\"]\n",
        "]\n",
        "\n",
        "# Treine o modelo Word2Vec\n",
        "model = Word2Vec(sentences, min_count=1)\n",
        "\n",
        "# Obtenha o vetor de uma palavra\n",
        "vector = model.wv['gato']\n",
        "# print(vector)\n",
        "\n",
        "# # Calcule a similaridade entre duas palavras\n",
        "similarity = model.wv.similarity('gato', 'gramado')\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4SyGsUmgYBl",
        "outputId": "2c0b6fe0-a6bc-499b-eca8-bbaba28db01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.052346744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 2\n"
      ],
      "metadata": {
        "id": "E5kbWwUtlgZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Mais frases para melhor treinamento\n",
        "sentences = [\n",
        "    [\"O\", \"gato\", \"subiu\", \"na\", \"árvore\"],\n",
        "    [\"O\", \"cachorro\", \"latiu\", \"para\", \"o\", \"gato\"],\n",
        "    [\"A\", \"bola\", \"rolou\", \"pelo\", \"gramado\"],\n",
        "    [\"O\", \"gato\", \"bebeu\", \"leite\"],\n",
        "    [\"O\", \"cachorro\", \"correu\", \"no\", \"parque\"]\n",
        "]\n",
        "\n",
        "# Treinando o modelo com mais parâmetros\n",
        "model = Word2Vec(\n",
        "    sentences,\n",
        "    min_count=1,        # Frequência mínima das palavras\n",
        "    vector_size=100,    # Tamanho do vetor\n",
        "    window=5,           # Tamanho da janela de contexto\n",
        "    sg=0               # 0 para CBOW, 1 para Skip-gram\n",
        ")\n",
        "\n",
        "# Obtendo vetor\n",
        "vector = model.wv['gato']\n",
        "print(\"Vetor da palavra 'gato':\", vector[:5])  # Mostra só os 5 primeiros números\n",
        "\n",
        "# Similaridade\n",
        "similarity = model.wv.similarity('gato', 'cachorro')\n",
        "print(\"Similaridade entre 'gato' e 'cachorro':\", similarity)\n",
        "\n",
        "# Palavras mais similares\n",
        "similar_words = model.wv.most_similar('gato')\n",
        "print(\"Palavras mais similares a 'gato':\", similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnr-EAYJlihO",
        "outputId": "4b821e84-72c7-4c03-d5a4-a8e64cff596c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vetor da palavra 'gato': [-0.00861969  0.00366574  0.00518988  0.00574194  0.00746692]\n",
            "Similaridade entre 'gato' e 'cachorro': -0.02367166\n",
            "Palavras mais similares a 'gato': [('gramado', 0.16072483360767365), ('A', 0.15923379361629486), ('pelo', 0.13724760711193085), ('bebeu', 0.12300863116979599), ('correu', 0.08546062558889389), ('o', 0.06797593832015991), ('para', 0.03364057466387749), ('leite', 0.022314244881272316), ('na', 0.009391162544488907), ('bola', 0.008312082849442959)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numero1 = int(input(\"informe um valor inteiro: \"))\n",
        "numero2 = int(input(\"informe outro valor: \"))\n",
        "soma = numero1 + numero2\n",
        "print(soma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dY_5nfv1OVK",
        "outputId": "4b0f49a9-4f11-4f84-88c9-5c5436844e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "informe um valor inteiro: 10\n",
            "informe outro valor: 20\n",
            "30\n"
          ]
        }
      ]
    }
  ]
}